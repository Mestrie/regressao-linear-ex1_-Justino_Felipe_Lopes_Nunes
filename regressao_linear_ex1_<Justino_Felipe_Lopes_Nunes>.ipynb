{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNochrvqsjuY2KajcNP78x6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mestrie/regressao-linear-ex1_-Justino_Felipe_Lopes_Nunes/blob/main/regressao_linear_ex1_%3CJustino_Felipe_Lopes_Nunes%3E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions\n",
        "------------------------------------------------------\n",
        "###compute_cost.py"
      ],
      "metadata": {
        "id": "lSxZyiP-atvM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "prt_nWZLXCjb"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "@file compute_cost.py\n",
        "@brief Computes the cost for linear regression.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def compute_cost(X, y, theta):\n",
        "    \"\"\"\n",
        "    Compute the cost for linear regression.\n",
        "\n",
        "    This function calculates the mean squared error cost function J(θ) for linear regression:\n",
        "    J(θ) = (1 / (2 * m)) * Σ (h(θ) - y)^2\n",
        "\n",
        "    where:\n",
        "    - J(θ) is the cost\n",
        "    - m is the number of training examples\n",
        "    - h(θ) is the hypothesis function (X @ theta)\n",
        "    - y is the vector of observed values\n",
        "\n",
        "    @param X: np.ndarray\n",
        "        Feature matrix including the intercept term (shape: m x n).\n",
        "    @param y: np.ndarray\n",
        "        Target variable vector (shape: m,).\n",
        "    @param theta: np.ndarray\n",
        "        Parameter vector for linear regression (shape: n,).\n",
        "\n",
        "    @return: float\n",
        "        The computed cost value as a single float.\n",
        "    \"\"\"\n",
        "\n",
        "    # get the number of training examples\n",
        "    m = len(y)\n",
        "\n",
        "    # Compute the predictions using the linear model by formula h(θ) = X @ θ\n",
        "    h_o = X @ theta\n",
        "\n",
        "    # Compute the error vector between predictions and actual values\n",
        "    errors = h_o - y\n",
        "\n",
        "    # Compute the cost as the mean squared error cost function using the formula\n",
        "    J_o = (1 / (2 * m)) * np.sum(errors**2)\n",
        "\n",
        "    return J_o\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gradient_descent.py\n",
        "\n"
      ],
      "metadata": {
        "id": "TnVYBDFki04f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@file gradient_descent.py\n",
        "@brief Implementa o algoritmo de descida do gradiente para regressão linear.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def gradient_descent(X, y, theta, alpha, num_iters):\n",
        "    \"\"\"\n",
        "    Executa a descida do gradiente para minimizar a função de custo J(θ)\n",
        "    no contexto de regressão linear.\n",
        "\n",
        "    @return: tuple[np.ndarray, np.ndarray]\n",
        "        theta: vetor otimizado de parâmetros (n,).\n",
        "        J_history: vetor com o histórico do valor da função de custo em cada iteração (num_iters,).\n",
        "        theta_history: parâmetros em cada iteração (num_iters+1, n).\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtem o número de amostras\n",
        "    m = len(y)\n",
        "\n",
        "    # Inicializa o vetor de custo J_history\n",
        "    J_history = np.zeros(num_iters)\n",
        "\n",
        "    # Inicializa o vetor theta_history\n",
        "    theta_history = np.zeros((num_iters + 1, theta.shape[0]))\n",
        "\n",
        "    # Armazena os parâmetros iniciais\n",
        "    theta_history[0] = theta\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        # Calcula as previsões\n",
        "        predictions = X @ theta\n",
        "\n",
        "        # Calcula o erro\n",
        "        erro = predictions - y\n",
        "\n",
        "        # Calcula o gradiente\n",
        "        gradient = (1/m) * (X.T @ erro)\n",
        "\n",
        "        # Atualiza os parâmetros\n",
        "        theta = theta - alpha * gradient\n",
        "\n",
        "        # Armazena o custo da iteração atual\n",
        "        J_history[i] = compute_cost(X, y, theta)\n",
        "\n",
        "        # Armazena os parâmetros atualizados\n",
        "        theta_history[i + 1] = theta\n",
        "\n",
        "    return theta, J_history, theta_history\n"
      ],
      "metadata": {
        "id": "PRAfcMF_jCjR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot_data.py"
      ],
      "metadata": {
        "id": "YFHumjLUkKRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@file plot_data.py\n",
        "@brief Plots the data points.\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data(x, y):\n",
        "    \"\"\"\n",
        "    @brief Plot training data as red crosses.\n",
        "\n",
        "    @param x np.ndarray Independent variable (population)\n",
        "    @param y np.ndarray Dependent variable (profit)\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(x, y, 'rx', markersize=5)\n",
        "    plt.xlabel('Population of City in 10,000s')\n",
        "    plt.ylabel('Profit in $10,000s')\n",
        "    plt.title('Training Data')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_VnM2CH6kZwc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## warm_up_exercise.py"
      ],
      "metadata": {
        "id": "svPqxPLpnoga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@file warm_up_exercise.py\n",
        "@brief Returns a 5x5 identity matrix.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def warm_up_exercise1():\n",
        "    \"\"\"\n",
        "    @brief Create and return a 5x5 identity matrix.\n",
        "\n",
        "    @return np.ndarray Identity matrix (5x5)\n",
        "    \"\"\"\n",
        "    return np.eye(5)\n",
        "\n",
        "def warm_up_exercise2(m=5):\n",
        "    \"\"\"\n",
        "    @brief Cria um vetor coluna de 1s, utilizado como termo de bias (intercepto) em regressão linear.\n",
        "\n",
        "    @param m: int\n",
        "        Número de exemplos (linhas).\n",
        "\n",
        "    @return np.ndarray\n",
        "        Vetor de shape (m, 1) com todos os valores iguais a 1.\n",
        "    \"\"\"\n",
        "    return np.ones((m, 1))\n",
        "\n",
        "def warm_up_exercise3(x):\n",
        "    \"\"\"\n",
        "    @brief Adiciona uma coluna de 1s (bias) ao vetor de entrada x.\n",
        "\n",
        "    @param x: np.ndarray\n",
        "        Vetor unidimensional de shape (m,)\n",
        "\n",
        "    @return np.ndarray\n",
        "        Matriz de shape (m, 2), com a primeira coluna sendo 1s (bias) e a segunda os valores de x.\n",
        "    \"\"\"\n",
        "    # obtem o número de exemplos\n",
        "    m = len(x)\n",
        "    # Garante que x é um vetor coluna usando reshape. Use np.reshape\n",
        "    x = np.reshape(x, (m, 1))\n",
        "    # Adiciona uma coluna de 1s (bias) ao vetor x. Use np.ones para criar um vetor de 1s\n",
        "    bias = np.ones((m, 1))\n",
        "    # Concatena a coluna de 1s (bias) com o vetor x. Use np.hstack para concatenar horizontalmente e retorne\n",
        "    return np.hstack((bias, x))\n",
        "\n",
        "def warm_up_exercise4(X, theta):\n",
        "    \"\"\"\n",
        "    @brief Realiza a multiplicação matricial entre X e θ, simulando h(θ) = X @ θ.\n",
        "\n",
        "    @param X: np.ndarray\n",
        "        Matriz de entrada de shape (m, n)\n",
        "\n",
        "    @param theta: np.ndarray\n",
        "        Vetor de parâmetros de shape (n,)\n",
        "\n",
        "    @return np.ndarray\n",
        "        Vetor de predições (m,)\n",
        "    \"\"\"\n",
        "    # retorna o resultado da multiplicação matricial entre X e θ\n",
        "    return X @ theta\n",
        "\n",
        "def warm_up_exercise5(predictions, y):\n",
        "    \"\"\"\n",
        "    @brief Calcula o vetor de erros quadráticos (squared errors) entre as predições e os valores reais.\n",
        "\n",
        "    @param predictions: np.ndarray\n",
        "        Vetor de predições (m,)\n",
        "\n",
        "    @param y: np.ndarray\n",
        "        Vetor de valores reais (m,)\n",
        "\n",
        "    @return np.ndarray\n",
        "        Vetor com os erros quadráticos: (pred - y)^2\n",
        "    \"\"\"\n",
        "    # Calcula o vetor de erros quadráticos (squared errors) entre as predições e os valores reais\n",
        "    # O vetor de erros quadráticos é calculado como a diferença entre as predições e os valores reais\n",
        "    return (predictions - y) ** 2\n",
        "\n",
        "def warm_up_exercise6(errors):\n",
        "    \"\"\"\n",
        "    @brief Calcula o custo médio (mean cost) a partir dos erros quadráticos.\n",
        "\n",
        "    @param errors: np.ndarray\n",
        "        Vetor de erros quadráticos (m,)\n",
        "\n",
        "    @return float\n",
        "        Custo médio (mean cost)\n",
        "    \"\"\"\n",
        "    # O custo médio é calculado como a média dos erros quadráticos\n",
        "    # Obtenha usando np.mean e não esqueça de dividir por 2\n",
        "    return np.mean(errors) / 2\n",
        "\n",
        "def warm_up_exercise7(X, y, theta):\n",
        "    \"\"\"\n",
        "    @brief Calcula o custo médio (mean cost) para um modelo de regressão linear.\n",
        "\n",
        "    @param X: np.ndarray\n",
        "        Matriz de entrada de shape (m, n)\n",
        "\n",
        "    @param y: np.ndarray\n",
        "        Vetor de valores reais (m,)\n",
        "\n",
        "    @param theta: np.ndarray\n",
        "        Vetor de parâmetros de shape (n,)\n",
        "\n",
        "    @return float\n",
        "        Custo médio (mean cost)\n",
        "    \"\"\"\n",
        "    # Use as funções auxiliares para calcular o custo médio\n",
        "    # 1. Calcule as predições usando a função warm_up_exercise4\n",
        "    # 2. Calcule os erros quadráticos usando a função warm_up_exercise5\n",
        "    # 3. Calcule o custo médio usando a função warm_up_exercise6\n",
        "    # 4. Retorne o custo médio\n",
        "    predictions = warm_up_exercise4(X, theta)\n",
        "    errors = warm_up_exercise5(predictions, y)\n",
        "    return warm_up_exercise6(errors)\n"
      ],
      "metadata": {
        "id": "eLCH5Jl_nukj"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}